#!/bin/bash

# Tokenizer Training Script
# This script trains a custom tokenizer for machine learning models

set -e  # Exit on any error

echo "üî§ Starting tokenizer training..."
echo

# Check if processed data exists
if [ ! -f "benign_processed.csv" ] || [ ! -f "malicious_processed.csv" ]; then
    echo "‚ùå Error: Processed data files not found"
    echo "   Please run preprocess_data.sh first to generate processed data"
    exit 1
fi

echo "‚úÖ Processed data files found"
echo

# Set configurable parameters
TOTAL_TOKENS=${TOTAL_TOKENS:-15000}

# Train custom tokenizer
echo "üöÄ Training custom tokenizer..."
echo "   ‚Ä¢ Training on: benign_processed.csv, malicious_processed.csv"
echo "   ‚Ä¢ Total tokens: ${TOTAL_TOKENS}"
echo "   ‚Ä¢ Output directory: malwi_models/"
echo

uv run python -m src.research.train_tokenizer \
    -b benign_processed.csv \
    -m malicious_processed.csv \
    -o malwi_models \
    --top-n-tokens ${TOTAL_TOKENS} \
    --save-computed-tokens \
    --force-retrain

echo
echo "üéâ Tokenizer training completed successfully!"
echo
echo "üìã Generated files in malwi_models/:"
echo "   ‚Ä¢ tokenizer.json - Main tokenizer configuration"
echo "   ‚Ä¢ tokenizer_config.json - Tokenizer metadata"
echo "   ‚Ä¢ vocab.json - Vocabulary mapping"
echo "   ‚Ä¢ merges.txt - BPE merge rules"
echo "   ‚Ä¢ computed_special_tokens.txt - All special tokens (base + data)"
echo "   ‚Ä¢ base_tokens_from_function_mapping.txt - Base tokens only"
echo
echo "üìñ Next steps:"
echo "   ‚Ä¢ Review computed_special_tokens.txt if needed"
echo "   ‚Ä¢ Run train_distilbert.sh to train the DistilBERT model"
echo "   ‚Ä¢ The tokenizer will be automatically loaded from malwi_models/"
echo